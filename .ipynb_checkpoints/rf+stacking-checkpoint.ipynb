{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "Survived       891 non-null int64\n",
      "Age            891 non-null float64\n",
      "Fare           891 non-null float64\n",
      "Pclass_2       891 non-null uint8\n",
      "Pclass_3       891 non-null uint8\n",
      "Embarked_Q     891 non-null uint8\n",
      "Embarked_S     891 non-null uint8\n",
      "Sex_male       891 non-null uint8\n",
      "Family_size    891 non-null int64\n",
      "dtypes: float64(2), int64(2), uint8(5)\n",
      "memory usage: 32.3 KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      "Age            418 non-null float64\n",
      "Fare           418 non-null float64\n",
      "Pclass_2       418 non-null uint8\n",
      "Pclass_3       418 non-null uint8\n",
      "Embarked_Q     418 non-null uint8\n",
      "Embarked_S     418 non-null uint8\n",
      "Sex_male       418 non-null uint8\n",
      "Family_size    418 non-null int64\n",
      "dtypes: float64(2), int64(1), uint8(5)\n",
      "memory usage: 11.9 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Family_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_2  Pclass_3  Embarked_Q  Embarked_S  \\\n",
       "0         0  22.0   7.2500         0         1           0           1   \n",
       "1         1  38.0  71.2833         0         0           0           0   \n",
       "2         1  26.0   7.9250         0         1           0           1   \n",
       "3         1  35.0  53.1000         0         0           0           1   \n",
       "4         0  35.0   8.0500         0         1           0           1   \n",
       "\n",
       "   Sex_male  Family_size  \n",
       "0         1            1  \n",
       "1         0            1  \n",
       "2         0            0  \n",
       "3         0            1  \n",
       "4         1            0  "
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('all/train.csv')\n",
    "df_test = pd.read_csv('all/test.csv')\n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def scaling(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    features = scaler.transform(data)\n",
    "    return features\n",
    "\n",
    "def manipulate_data(data):\n",
    "    \n",
    "    data = data.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1)\n",
    "    data = pd.get_dummies(data, columns = ['Pclass','Embarked','Sex'],drop_first=True)\n",
    "\n",
    "    # fill missingdata\n",
    "    mean_age = data.Age.median()\n",
    "    data.Age = data.Age.fillna(mean_age)\n",
    "\n",
    "    mean_fare = data.Fare.median()\n",
    "    data.Fare = data.Fare.fillna(mean_fare)\n",
    "\n",
    "    # feature combining\n",
    "    data['Family_size'] = data.Parch + data.SibSp\n",
    "    data = data.drop(['Parch', 'SibSp'], axis=1)\n",
    "    \n",
    "    # drop useless and distracting features\n",
    "    #data = data.drop(['Embarked_Q', 'Pclass_2'], axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "df_train = manipulate_data(df_train)\n",
    "df_train.info()\n",
    "df_train.head()\n",
    "\n",
    "print('\\n')\n",
    "df_test = manipulate_data(df_test)\n",
    "df_test.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single-layer stacking\n",
    "from sklearn.model_selection import KFold\n",
    "class SingleLayerStacking(object):\n",
    "    def __init__(self, n_folds, base_models):\n",
    "        self.n_folds = n_folds\n",
    "        self.base_models = base_models\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            self.base_models[i].fit(X_train, y_train)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        S_pred = np.zeros((len(self.base_models), X.shape[0]))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            S_pred[i] = model.predict(X)\n",
    "        S_pred = S_pred.T.astype(int)\n",
    "        y_predict = np.zeros(S_pred.shape[0])\n",
    "        for example in range(S_pred.shape[0]):\n",
    "            y_predict[example] = np.argmax(np.bincount(S_pred[example]))\n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 8) (800,) (91, 8) (91,)\n",
      "\n",
      " [[ 48.      34.375    0.     ...   1.       0.       4.    ]\n",
      " [ 28.       7.75     0.     ...   0.       1.       0.    ]\n",
      " [ 28.       7.8292   0.     ...   0.       1.       0.    ]\n",
      " ...\n",
      " [ 30.      12.35     1.     ...   0.       0.       0.    ]\n",
      " [ 28.       7.8958   0.     ...   1.       1.       0.    ]\n",
      " [ 17.     110.8833   0.     ...   0.       1.       2.    ]]\n",
      "\n",
      " (418, 8)\n",
      "\n",
      " [[34.5     7.8292  0.     ...  0.      1.      0.    ]\n",
      " [47.      7.      0.     ...  1.      0.      1.    ]\n",
      " [62.      9.6875  1.     ...  0.      1.      0.    ]\n",
      " ...\n",
      " [38.5     7.25    0.     ...  1.      1.      0.    ]\n",
      " [27.      8.05    0.     ...  1.      1.      0.    ]\n",
      " [27.     22.3583  0.     ...  0.      1.      2.    ]]\n"
     ]
    }
   ],
   "source": [
    "value = df_train.values\n",
    "np.random.shuffle(value)\n",
    "X = value[:, 1:]\n",
    "X_sc = scaling(X)\n",
    "y = value[:, 0]\n",
    "y_train = value[:800, 0]\n",
    "y_val = value[800:, 0]\n",
    "\n",
    "X_train = X[:800]\n",
    "X_train_sc = scaling(X_train)\n",
    "X_val = X[800:]\n",
    "X_val_sc = scaling(X_val)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "print('\\n',X)\n",
    "\n",
    "X_test = df_test.values\n",
    "X_test_sc = scaling(X_test)\n",
    "print('\\n', X_test.shape)\n",
    "print('\\n',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_1 = SVC(20)\n",
    "svc_2 = SVC(20)\n",
    "rfc_1 = RandomForestClassifier(n_estimators=100, max_depth=6)\n",
    "rfc_2 = RandomForestClassifier(n_estimators=100, max_depth=7)\n",
    "rfc_3 = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "stacking = SingleLayerStacking(n_folds=5, base_models=[svc_1, svc_2, rfc_1, rfc_2, rfc_3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stacking:\n",
      " [0.83798883 0.84831461 0.82022472 0.76966292 0.84831461]\n",
      "0.8249011361496453\n",
      "\n",
      "svc_1:\n",
      " [0.82122905 0.83240223 0.80337079 0.80898876 0.80225989]\n",
      "0.8136501444967298\n",
      "\n",
      "svc_2:\n",
      " [0.82122905 0.83240223 0.80337079 0.80898876 0.80225989]\n",
      "0.8136501444967298\n",
      "\n",
      "rfc_1:\n",
      " [0.83240223 0.82681564 0.8258427  0.82022472 0.81355932]\n",
      "0.8237689229718417\n",
      "\n",
      "rfc_2:\n",
      " [0.8547486  0.83798883 0.83146067 0.83146067 0.83050847]\n",
      "0.837233450611695\n",
      "\n",
      "rfc_3:\n",
      " [0.84357542 0.82122905 0.8258427  0.81460674 0.79661017]\n",
      "0.8203728153935032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "scores_stacking = np.zeros(5)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_sc)):\n",
    "    X_train_i, X_test_i = X_sc[train_index], X_sc[test_index]\n",
    "    y_train_i, y_test_i = y[train_index], y[test_index]\n",
    "    stacking.fit(X_train_i, y_train_i)\n",
    "    scores_stacking[i] = accuracy_score(y_test_i, stacking.predict(X_test_i))\n",
    "print('\\nstacking:\\n', scores_stacking)\n",
    "print(scores_stacking.mean())\n",
    "\n",
    "scores_svc_1 = cross_val_score(svc_1, X_sc, y, cv=5, scoring='accuracy')\n",
    "print('\\nsvc_1:\\n', scores_svc_1)\n",
    "print(scores_svc_1.mean())\n",
    "\n",
    "scores_svc_2 = cross_val_score(svc_2, X_sc, y, cv=5, scoring='accuracy')\n",
    "print('\\nsvc_2:\\n', scores_svc_2)\n",
    "print(scores_svc_2.mean())\n",
    "\n",
    "scores_rfc_1 = cross_val_score(rfc_1, X, y, cv=5, scoring='accuracy')\n",
    "print('\\nrfc_1:\\n', scores_rfc_1)\n",
    "print(scores_rfc_1.mean())\n",
    "\n",
    "scores_rfc_2 = cross_val_score(rfc_2, X, y, cv=5, scoring='accuracy')\n",
    "print('\\nrfc_2:\\n', scores_rfc_2)\n",
    "print(scores_rfc_2.mean())\n",
    "\n",
    "scores_rfc_3 = cross_val_score(rfc_3, X, y, cv=5, scoring='accuracy')\n",
    "print('\\nrfc_3:\\n', scores_rfc_3)\n",
    "print(scores_rfc_3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "selective_model = rfc_1\n",
    "selective_model.fit(X_sc, y)\n",
    "predict_y = selective_model.predict(X_test_sc)\n",
    "result = pd.Series(predict_y, np.arange(418)+ 892, dtype=int, name='Survived')\n",
    "result.to_csv('result.csv', index_label='PassengerId',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-layer stacking\n",
    "from sklearn.cross_validation import KFold\n",
    "class MultiLayerStacking(object):\n",
    "    def __init__(self, n_folds, stacker, base_models):\n",
    "        self.n_folds = n_folds\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    # X为training features, y为training groundtruth，T为测试\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "        from sklearn.cross_validation import KFold\n",
    "\n",
    "        folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=True, random_state=2016))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        # for each layer\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            S_test_i = np.zeros((T.shape[0], len(folds)))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                # y_holdout = y[test_idx]\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_holdout)[:]\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict(T)[:]\n",
    "\n",
    "            S_test[:, i] = S_test_i.mean(1)\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        y_pred = self.stacker.predict(S_test)[:]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "svc_3 = SVC(20)\n",
    "svc_4 = SVC(20)\n",
    "rfc_4 = RandomForestClassifier(n_estimators=100, max_depth=6)\n",
    "rfc_5 = RandomForestClassifier(n_estimators=100, max_depth=7)\n",
    "rfc_6 = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "log_stacker = RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "multi_stacking = MultiLayerStacking(n_folds=5, stacker=log_stacker ,base_models=[svc_3, svc_4, rfc_4, rfc_5, rfc_6] )\n",
    "y_pred = multi_stacking.fit_predict(X_sc, y, X_test_sc)\n",
    "result = pd.Series(y_pred, np.arange(418)+ 892, dtype=int, name='Survived')\n",
    "result.to_csv('multi_result.csv', index_label='PassengerId',header=True)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "multi_stacking:\n",
      " [0.81564246 0.82022472 0.87078652 0.78651685 0.83707865]\n",
      "0.8260498399347185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "scores_multi_stacking = np.zeros(5)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_sc)):\n",
    "    X_train_i, X_test_i = X_sc[train_index], X_sc[test_index]\n",
    "    y_train_i, y_test_i = y[train_index], y[test_index]\n",
    "    y_pred_i = multi_stacking.fit_predict(X_train_i, y_train_i, X_test_i)\n",
    "    scores_multi_stacking[i] = accuracy_score(y_test_i, y_pred_i)\n",
    "print('\\nmulti_stacking:\\n', scores_multi_stacking)\n",
    "print(scores_multi_stacking.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
